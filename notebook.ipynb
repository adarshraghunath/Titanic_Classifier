{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.read_csv('./train.csv')\n",
    "test_file = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat([train_file,test_file],axis=0) #Concatenate for efficient feature engineering.\n",
    "total_data.reset_index(inplace=True)\n",
    "total_data = total_data.drop(columns=['index','PassengerId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0       0.0       3                            Braund, Mr. Owen Harris   \n",
       "1       1.0       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2       1.0       3                             Heikkinen, Miss. Laina   \n",
       "3       1.0       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4       0.0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148', 'B45', 'B36', 'A21', 'D34', 'A9', 'C31', 'B61', 'C53',\n",
       "       'D43', 'C130', 'C132', 'C55 C57', 'C116', 'F', 'A29', 'C6', 'C28',\n",
       "       'C51', 'C97', 'D22', 'B10', 'E45', 'E52', 'A11', 'B11', 'C80',\n",
       "       'C89', 'F E46', 'B26', 'F E57', 'A18', 'E60', 'E39 E41',\n",
       "       'B52 B54 B56', 'C39', 'B24', 'D40', 'D38', 'C105'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data[\"Cabin\"].unique()\n",
    "X_test['Deck'] = X_test['Cabin'].str.extract('([A-Za-z])')\n",
    "X_test.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_col = pd.DataFrame([i.split(',')[1].split('.')[0].strip() for i in total_data.Name],columns=['Title'])\n",
    "\n",
    "extract = lambda n : n.split(',')[1].split('.')[0].strip()\n",
    "\n",
    "total_data['Title']  = total_data['Name'].map(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Royalty\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}\n",
    "\n",
    "total_data['Title']= total_data.Title.map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([total_data[total_data['Survived'] == 1]['Fare'], total_data[total_data['Survived'] == 0]['Fare']],color=['b','r'], label=['Survived','Dead'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"Sex\",\"Embarked\",\"Title\"] # [\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]\n",
    "numerical_features = ['Age','Pclass', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZE and MANIPULATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOX PLOT, SCATTER PLOT etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transforms():\n",
    "    def __init__(self, categorical_features : list[str], numerical_features : list[str]) -> None:\n",
    "        self.cat = categorical_features\n",
    "        self.num = numerical_features\n",
    "        self.imputer = SimpleImputer(strategy='mean')\n",
    "        self.imputer_cat = SimpleImputer(strategy='most_frequent') \n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore',min_frequency=5)\n",
    "\n",
    "    \n",
    "    def __call__(self, file : pd.DataFrame):\n",
    "        file[self.num] = self.imputer.fit_transform(file[self.num])\n",
    "        file[self.num] = self.scaler.fit_transform(file[self.num])\n",
    "        file[self.cat] = self.imputer_cat.fit_transform(file[self.cat])\n",
    "        encoded = self.encoder.fit_transform(file[self.cat])\n",
    "        col_names = self.encoder.get_feature_names_out(self.cat)\n",
    "        encoded = pd.DataFrame(encoded.toarray(),columns=col_names)\n",
    "        features = pd.concat([file, encoded], axis=1).drop(self.cat, axis=1)\n",
    "        \n",
    "        return features\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,features : pd.DataFrame ,transform = None, training= True, **kwargs) -> None:  #labels : pd.Series\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        if training:\n",
    "            self.labels = kwargs.get('labels',None)\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.training:\n",
    "            sample = {'features': torch.tensor(self.features.values[index],dtype=torch.float32),'labels': torch.tensor(self.labels.iloc[index],dtype=torch.float32)}\n",
    "        else:\n",
    "            sample = {'features': torch.tensor(self.features.values[index],dtype=torch.float32)}\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/tq7t7v651kdg4wr4_3hgcjd00000gn/T/ipykernel_7327/2884726106.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop(columns=['Ticket','Cabin'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = Transforms(categorical_features=categorical_features,numerical_features=numerical_features)\n",
    "\n",
    "y_total = total_data[\"Survived\"]\n",
    "X_total = total_data.drop(columns=['Survived','Name'])\n",
    "\n",
    "X_total = transform(X_total)\n",
    "\n",
    "#TRAIN DATA\n",
    "X = X_total[:891]\n",
    "y = y_total[:891]\n",
    "\n",
    "#TEST DATA\n",
    "X_test = X_total[891:]\n",
    "X_test.drop(columns=['Ticket','Cabin'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['Cabin','Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train,  labels= y_train, transform=transform)\n",
    "val_dataset = CustomDataset(X_val, labels = y_val, transform=transform)\n",
    "\n",
    "# Use DataLoader for batching and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TitanicModel, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, 16)\n",
    "        self.bn1 = nn.BatchNorm1d(16)  #Batchnorm best when applied before activation function\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)  #use dropout after activation  CONV / Dense -> BN -> ReLU -> Dropout\n",
    "        self.l2 = nn.Linear(16,32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.f1= nn.Flatten()\n",
    "        self.l3 = nn.Linear(32, 16)  # Output layer with 1 neuron for binary classification\n",
    "        \n",
    "        self.l4 = nn.Linear(16,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l4(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val epoch : 100, val loss : 0.17704473435878754\n",
      "Val epoch : 200, val loss : 0.18148790299892426\n",
      "Val epoch : 300, val loss : 0.21065418422222137\n",
      "Val epoch : 400, val loss : 0.22178776562213898\n",
      "Val epoch : 500, val loss : 0.21202929317951202\n",
      "Val epoch : 600, val loss : 0.19529074430465698\n",
      "Val epoch : 700, val loss : 0.2454066276550293\n",
      "Val epoch : 800, val loss : 0.21798807382583618\n",
      "Val epoch : 900, val loss : 0.19890768826007843\n",
      "Val epoch : 1000, val loss : 0.20251309871673584\n"
     ]
    }
   ],
   "source": [
    "#Train Loop\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = TitanicModel(input_size)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=1e-3)\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for item, train_set in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        feature,label = train_set['features'],train_set['labels']\n",
    "        output = model(feature)\n",
    "        l = loss(output.squeeze(),label)\n",
    "\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    # print(f'Epoch [{epoch + 1}/{epochs}], Loss: {l.item()}')\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        model.eval()\n",
    "        for item, val_set in enumerate(val_loader):\n",
    "            v_feature,v_label = val_set['features'],val_set['labels']\n",
    "            val_output = model(v_feature)\n",
    "            v_l = loss(val_output.squeeze(),v_label)\n",
    "        print(f'Val epoch : {epoch+1}, val loss : {v_l.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(X_test,training=False)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_transformed = transform(test_data)\n",
    "\n",
    "# test_data_transformed = test_data_transformed.drop(columns=['Name','Ticket','Cabin','PassengerId'])\n",
    "\n",
    "\n",
    "\n",
    "predictions = [] \n",
    "model.eval()\n",
    "for i,item in enumerate(test_loader):\n",
    "    op = model(item['features'])\n",
    "    prob = torch.sigmoid(op)  #Calc probabilities\n",
    "    # print(prob)\n",
    "    binary_pred = (prob>0.5).int()\n",
    "    predictions.append(binary_pred)\n",
    "\n",
    "predictions = torch.cat(predictions,dim=0)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_id = test_file['PassengerId'].values\n",
    "pass_id = pass_id.reshape(-1,1)\n",
    "fin = np.concatenate([pass_id,predictions],axis=1)\n",
    "fin = pd.DataFrame(fin,columns=['PassengerId','Survived'])\n",
    "fin.to_csv(path_or_buf='submission_10.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('workenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fea2c95cd02741c99686591c6bc73d04fc339f47e4f32310a05414b4cc90ff15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
